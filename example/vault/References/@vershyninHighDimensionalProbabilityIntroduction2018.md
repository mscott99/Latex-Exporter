---
type: book
year: 2018
authors: [Roman Vershynin]
publisher: Cambridge University Press
title: High-Dimensional Probability: An Introduction with Applications in Data Science
ctime: 2023-12-28
mtime: 2024-05-17
---

#literature
# High-Dimensional Probability: An Introduction with Applications in Data Science
See the PDF: [Vershynin - 2018 - High-Dimensional Probability An Introduction with.pdf](zotero://select/library/items/EJFK8JUU)
## Literature Note
%% begin notes %%
Proposition 2.1.2
$$
  \left(\frac{1}{t} - \frac{1}{t^3}\right) \frac{1}{ \sqrt{2\pi}} e^{-t^2/2} \le \mathbb{P} \{ g \ge t\} \le \frac{1}{t} \frac{1}{\sqrt{2\pi}} e^{-t^2/2}.
$$
%% end notes %%
## Zotero Annotations
**Imported: 2023-02-05**

> “(Matrix Bernstein inequality)” Yellow Highlight [Page 128](zotero://open-pdf/library/items/EJFK8JUU?page=128)

Matrix Bernstein

> “Theorem 7.2.11 (Sudakov–Fernique inequality)” Yellow Highlight [Page 171](zotero://open-pdf/library/items/EJFK8JUU?page=171)

> “Theorem 7.4.1 (Sudakov’s minoration inequality)” Yellow Highlight [Page 175](zotero://open-pdf/library/items/EJFK8JUU?page=175)

> “Dudley’s inequality for sets in Rn)” Yellow Highlight [Page 196](zotero://open-pdf/library/items/EJFK8JUU?page=196)

Dudley in R
## Abstract
High-dimensional probability offers insight into the behavior of random vectors, random matrices, random subspaces, and objects used to quantify uncertainty in high dimensions. Drawing on ideas from probability, analysis, and geometry, it lends itself to applications in mathematics, statistics, theoretical computer science, signal processing, optimization, and more. It is the first to integrate theory, key tools, and modern applications of high-dimensional probability. Concentration inequalities form the core, and it covers both classical results such as Hoeffding's and Chernoff's inequalities and modern developments such as the matrix Bernstein's inequality. It then introduces the powerful methods based on stochastic processes, including such tools as Slepian's, Sudakov's, and Dudley's inequalities, as well as generic chaining and bounds based on VC dimension. A broad range of illustrations is embedded throughout, including classical and modern results for covariance estimation, clustering, networks, semidefinite programming, coding, dimension reduction, matrix completion, machine learning, compressed sensing, and sparse regression.

%% Import Date: 2023-02-05T17:52:51.268-08:00 %%
